# eye-for-blind
This deep learning model uses an attention mechanism on the Flickr8K dataset to explain image contents through speech caption generation. Designed for blind people, it enables image comprehension via speech. A CNN-RNN model generates captions, then a text to speech library converts them to speech
